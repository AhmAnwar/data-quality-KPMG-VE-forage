{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:16.327089Z",
     "iopub.status.busy": "2023-07-27T13:23:16.326340Z",
     "iopub.status.idle": "2023-07-27T13:23:17.437178Z",
     "shell.execute_reply": "2023-07-27T13:23:17.435986Z",
     "shell.execute_reply.started": "2023-07-27T13:23:16.326749Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:17.444005Z",
     "iopub.status.busy": "2023-07-27T13:23:17.443571Z",
     "iopub.status.idle": "2023-07-27T13:23:18.844585Z",
     "shell.execute_reply": "2023-07-27T13:23:18.843441Z",
     "shell.execute_reply.started": "2023-07-27T13:23:17.443964Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'https://docs.google.com/spreadsheets/d/1j98KDlHYqBzhmPagBuy27XoeZdXTFBPM/edit?usp=drive_link&ouid=107285189322376229505&rtpof=true&sd=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_excel in module pandas.io.excel._base:\n",
      "\n",
      "read_excel(io, sheet_name: 'str | int | list[IntStrT] | None' = 0, *, header: 'int | Sequence[int] | None' = 0, names: 'list[str] | None' = None, index_col: 'int | Sequence[int] | None' = None, usecols: 'int | str | Sequence[int] | Sequence[str] | Callable[[str], bool] | None' = None, squeeze: 'bool | None' = None, dtype: 'DtypeArg | None' = None, engine: \"Literal['xlrd', 'openpyxl', 'odf', 'pyxlsb'] | None\" = None, converters: 'dict[str, Callable] | dict[int, Callable] | None' = None, true_values: 'Iterable[Hashable] | None' = None, false_values: 'Iterable[Hashable] | None' = None, skiprows: 'Sequence[int] | int | Callable[[int], object] | None' = None, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, parse_dates: 'list | dict | bool' = False, date_parser: 'Callable | None' = None, thousands: 'str | None' = None, decimal: 'str' = '.', comment: 'str | None' = None, skipfooter: 'int' = 0, convert_float: 'bool | None' = None, mangle_dupe_cols: 'bool' = True, storage_options: 'StorageOptions' = None) -> 'DataFrame | dict[IntStrT, DataFrame]'\n",
      "    Read an Excel file into a pandas DataFrame.\n",
      "    \n",
      "    Supports `xls`, `xlsx`, `xlsm`, `xlsb`, `odf`, `ods` and `odt` file extensions\n",
      "    read from a local filesystem or URL. Supports an option to read\n",
      "    a single sheet or a list of sheets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be: ``file://localhost/path/to/table.xlsx``.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method,\n",
      "        such as a file handle (e.g. via builtin ``open`` function)\n",
      "        or ``StringIO``.\n",
      "    sheet_name : str, int, list, or None, default 0\n",
      "        Strings are used for sheet names. Integers are used in zero-indexed\n",
      "        sheet positions (chart sheets do not count as a sheet position).\n",
      "        Lists of strings/integers are used to request multiple sheets.\n",
      "        Specify None to get all worksheets.\n",
      "    \n",
      "        Available cases:\n",
      "    \n",
      "        * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
      "        * ``1``: 2nd sheet as a `DataFrame`\n",
      "        * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
      "        * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
      "          as a dict of `DataFrame`\n",
      "        * None: All worksheets.\n",
      "    \n",
      "    header : int, list of int, default 0\n",
      "        Row (0-indexed) to use for the column labels of the parsed\n",
      "        DataFrame. If a list of integers is passed those row positions will\n",
      "        be combined into a ``MultiIndex``. Use None if there is no header.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row,\n",
      "        then you should explicitly pass header=None.\n",
      "    index_col : int, list of int, default None\n",
      "        Column (0-indexed) to use as the row labels of the DataFrame.\n",
      "        Pass None if there is no such column.  If a list is passed,\n",
      "        those columns will be combined into a ``MultiIndex``.  If a\n",
      "        subset of data is selected with ``usecols``, index_col\n",
      "        is based on the subset.\n",
      "    \n",
      "        Missing values will be forward filled to allow roundtripping with\n",
      "        ``to_excel`` for ``merged_cells=True``. To avoid forward filling the\n",
      "        missing values use ``set_index`` after reading the data instead of\n",
      "        ``index_col``.\n",
      "    usecols : str, list-like, or callable, default None\n",
      "        * If None, then parse all columns.\n",
      "        * If str, then indicates comma separated list of Excel column letters\n",
      "          and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
      "          both sides.\n",
      "        * If list of int, then indicates list of column numbers to be parsed\n",
      "          (0-indexed).\n",
      "        * If list of string, then indicates list of column names to be parsed.\n",
      "        * If callable, then evaluate each column name against it and parse the\n",
      "          column if the callable returns ``True``.\n",
      "    \n",
      "        Returns a subset of the columns according to behavior above.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "           Append ``.squeeze(\"columns\")`` to the call to ``read_excel`` to squeeze\n",
      "           the data.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : str, default None\n",
      "        If io is not a buffer or path, this must be set to identify io.\n",
      "        Supported engines: \"xlrd\", \"openpyxl\", \"odf\", \"pyxlsb\".\n",
      "        Engine compatibility :\n",
      "    \n",
      "        - \"xlrd\" supports old-style Excel files (.xls).\n",
      "        - \"openpyxl\" supports newer Excel file formats.\n",
      "        - \"odf\" supports OpenDocument file formats (.odf, .ods, .odt).\n",
      "        - \"pyxlsb\" supports Binary Excel files.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "            The engine `xlrd <https://xlrd.readthedocs.io/en/latest/>`_\n",
      "            now only supports old-style ``.xls`` files.\n",
      "            When ``engine=None``, the following logic will be\n",
      "            used to determine the engine:\n",
      "    \n",
      "           - If ``path_or_buffer`` is an OpenDocument format (.odf, .ods, .odt),\n",
      "             then `odf <https://pypi.org/project/odfpy/>`_ will be used.\n",
      "           - Otherwise if ``path_or_buffer`` is an xls format,\n",
      "             ``xlrd`` will be used.\n",
      "           - Otherwise if ``path_or_buffer`` is in xlsb format,\n",
      "             ``pyxlsb`` will be used.\n",
      "    \n",
      "             .. versionadded:: 1.3.0\n",
      "           - Otherwise ``openpyxl`` will be used.\n",
      "    \n",
      "             .. versionchanged:: 1.3.0\n",
      "    \n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can\n",
      "        either be integers or column labels, values are functions that take one\n",
      "        input argument, the Excel cell content, and return the transformed\n",
      "        content.\n",
      "    true_values : list, default None\n",
      "        Values to consider as True.\n",
      "    false_values : list, default None\n",
      "        Values to consider as False.\n",
      "    skiprows : list-like, int, or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int) at the\n",
      "        start of the file. If callable, the callable function will be evaluated\n",
      "        against the row indices, returning True if the row should be skipped and\n",
      "        False otherwise. An example of a valid callable argument would be ``lambda\n",
      "        x: x in [0, 2]``.\n",
      "    nrows : int, default None\n",
      "        Number of rows to parse.\n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values. By default the following values are interpreted\n",
      "        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    parse_dates : bool, list-like, or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * bool. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index contains an unparsable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. If you don`t want to\n",
      "        parse some cells as date just change their type in Excel to \"Text\".\n",
      "        For non-standard datetime parsing, use ``pd.to_datetime`` after ``pd.read_excel``.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    thousands : str, default None\n",
      "        Thousands separator for parsing string columns to numeric.  Note that\n",
      "        this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point for parsing string columns to numeric.\n",
      "        Note that this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.(e.g. use ',' for European data).\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "    comment : str, default None\n",
      "        Comments out remainder of line. Pass a character or characters to this\n",
      "        argument to indicate comments in the input file. Any data between the\n",
      "        comment string and the end of the current line is ignored.\n",
      "    skipfooter : int, default 0\n",
      "        Rows at the end to skip (0-indexed).\n",
      "    convert_float : bool, default True\n",
      "        Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
      "        data will be read in as floats: Excel stores all numbers as floats\n",
      "        internally.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "            convert_float will be removed in a future version\n",
      "    \n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    \n",
      "        .. deprecated:: 1.5.0\n",
      "            Not implemented, and a new argument to specify the pattern for the\n",
      "            names of duplicated columns will be added instead\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or dict of DataFrames\n",
      "        DataFrame from the passed in Excel file. See notes in sheet_name\n",
      "        argument for more information on when a dict of DataFrames is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_excel : Write DataFrame to an Excel file.\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The file can be read using the file name as string or an open file object:\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1      1\n",
      "    1   string2      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    >>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
      "    ...               sheet_name='Sheet3')  # doctest: +SKIP\n",
      "       Unnamed: 0      Name  Value\n",
      "    0           0   string1      1\n",
      "    1           1   string2      2\n",
      "    2           2  #Comment      3\n",
      "    \n",
      "    Index and header can be specified via the `index_col` and `header` arguments\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
      "         0         1      2\n",
      "    0  NaN      Name  Value\n",
      "    1  0.0   string1      1\n",
      "    2  1.0   string2      2\n",
      "    3  2.0  #Comment      3\n",
      "    \n",
      "    Column types are inferred but can be explicitly specified\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1    1.0\n",
      "    1   string2    2.0\n",
      "    2  #Comment    3.0\n",
      "    \n",
      "    True, False, and NA values, and thousands separators have defaults,\n",
      "    but can be explicitly specified, too. Supply the values you would like\n",
      "    as strings or lists of strings!\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0       NaN      1\n",
      "    1       NaN      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
      "          Name  Value\n",
      "    0  string1    1.0\n",
      "    1  string2    2.0\n",
      "    2     None    NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m customer_address_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(io\u001b[38;5;241m=\u001b[39m path, engine\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124modf\u001b[39m\u001b[38;5;124m'\u001b[39m, sheet_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerAddress\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1695\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_odfreader.py:46\u001b[0m, in \u001b[0;36mODFReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     42\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m     43\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124modf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:545\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_odfreader.py:57\u001b[0m, in \u001b[0;36mODFReader.load_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_workbook\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m]):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01modf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopendocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load(filepath_or_buffer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\odf\\opendocument.py:982\u001b[0m, in \u001b[0;36mload\u001b[1;34m(odffile)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(odffile):\n\u001b[0;32m    976\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    Load an ODF file into memory\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m    @param odffile unicode string: name of a file, or as an alternative,\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    an open readable stream\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m    @return a reference to the structure (an OpenDocument instance)\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m     z \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(odffile)\n\u001b[0;32m    983\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m __detectmimetype(z, odffile)\n\u001b[0;32m    984\u001b[0m     doc \u001b[38;5;241m=\u001b[39m OpenDocument(mimetype, add_generator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile.py:1301\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_RealGetContents()\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile.py:1368\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "customer_address_df = pd.read_excel(io= path, engine= 'odf', sheet_name= 'CustomerAddress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:18.847058Z",
     "iopub.status.busy": "2023-07-27T13:23:18.846232Z",
     "iopub.status.idle": "2023-07-27T13:23:20.452512Z",
     "shell.execute_reply": "2023-07-27T13:23:20.451582Z",
     "shell.execute_reply.started": "2023-07-27T13:23:18.847015Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_demographic_df = pd.read_excel(path, sheet_name= 'CustomerDemographic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:20.456831Z",
     "iopub.status.busy": "2023-07-27T13:23:20.456253Z",
     "iopub.status.idle": "2023-07-27T13:23:27.008093Z",
     "shell.execute_reply": "2023-07-27T13:23:27.006946Z",
     "shell.execute_reply.started": "2023-07-27T13:23:20.456795Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_df = pd.read_excel(path, sheet_name= 'Transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# customer_address_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.009576Z",
     "iopub.status.busy": "2023-07-27T13:23:27.009262Z",
     "iopub.status.idle": "2023-07-27T13:23:27.025423Z",
     "shell.execute_reply": "2023-07-27T13:23:27.024119Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.009546Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_address_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.027763Z",
     "iopub.status.busy": "2023-07-27T13:23:27.027061Z",
     "iopub.status.idle": "2023-07-27T13:23:27.046287Z",
     "shell.execute_reply": "2023-07-27T13:23:27.044906Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.027728Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "customer_address_df.columns = customer_address_df.iloc[0]\n",
    "customer_address_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.048319Z",
     "iopub.status.busy": "2023-07-27T13:23:27.047886Z",
     "iopub.status.idle": "2023-07-27T13:23:27.066039Z",
     "shell.execute_reply": "2023-07-27T13:23:27.064896Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.048279Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop row[0]\n",
    "\n",
    "customer_address_df = customer_address_df.drop(index= 0, axis= 0)\n",
    "customer_address_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.069854Z",
     "iopub.status.busy": "2023-07-27T13:23:27.069480Z",
     "iopub.status.idle": "2023-07-27T13:23:27.085097Z",
     "shell.execute_reply": "2023-07-27T13:23:27.083929Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.069805Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset index\n",
    "\n",
    "customer_address_df = customer_address_df.reset_index().drop(columns= 'index', axis= 1)\n",
    "customer_address_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.087350Z",
     "iopub.status.busy": "2023-07-27T13:23:27.086824Z",
     "iopub.status.idle": "2023-07-27T13:23:27.101632Z",
     "shell.execute_reply": "2023-07-27T13:23:27.100658Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.087309Z"
    }
   },
   "outputs": [],
   "source": [
    "# check data types\n",
    "\n",
    "customer_address_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.103349Z",
     "iopub.status.busy": "2023-07-27T13:23:27.102960Z",
     "iopub.status.idle": "2023-07-27T13:23:27.118152Z",
     "shell.execute_reply": "2023-07-27T13:23:27.116943Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.103321Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert customer_id column to int\n",
    "\n",
    "customer_address_df['customer_id'] = customer_address_df['customer_id'].astype(int)\n",
    "customer_address_df['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.121786Z",
     "iopub.status.busy": "2023-07-27T13:23:27.119557Z",
     "iopub.status.idle": "2023-07-27T13:23:27.136235Z",
     "shell.execute_reply": "2023-07-27T13:23:27.134828Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.121743Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'postcode' column to int\n",
    "\n",
    "customer_address_df['postcode'] = customer_address_df['postcode'].astype(int)\n",
    "customer_address_df['postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.138345Z",
     "iopub.status.busy": "2023-07-27T13:23:27.137496Z",
     "iopub.status.idle": "2023-07-27T13:23:27.148116Z",
     "shell.execute_reply": "2023-07-27T13:23:27.147351Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.138315Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'property_valuation' column to int\n",
    "\n",
    "customer_address_df['property_valuation'] = customer_address_df['property_valuation'].astype(int)\n",
    "customer_address_df['property_valuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.153741Z",
     "iopub.status.busy": "2023-07-27T13:23:27.153194Z",
     "iopub.status.idle": "2023-07-27T13:23:27.164654Z",
     "shell.execute_reply": "2023-07-27T13:23:27.163897Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.153711Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_address_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.166582Z",
     "iopub.status.busy": "2023-07-27T13:23:27.165745Z",
     "iopub.status.idle": "2023-07-27T13:23:27.184738Z",
     "shell.execute_reply": "2023-07-27T13:23:27.183888Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.166534Z"
    }
   },
   "outputs": [],
   "source": [
    "# check NULL values\n",
    "\n",
    "customer_address_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.187051Z",
     "iopub.status.busy": "2023-07-27T13:23:27.186295Z",
     "iopub.status.idle": "2023-07-27T13:23:27.197029Z",
     "shell.execute_reply": "2023-07-27T13:23:27.195925Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.187020Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of duplicated values\n",
    "\n",
    "customer_address_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.198772Z",
     "iopub.status.busy": "2023-07-27T13:23:27.198421Z",
     "iopub.status.idle": "2023-07-27T13:23:27.208008Z",
     "shell.execute_reply": "2023-07-27T13:23:27.206904Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.198743Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of data validity\n",
    "\n",
    "customer_address_df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.210184Z",
     "iopub.status.busy": "2023-07-27T13:23:27.209430Z",
     "iopub.status.idle": "2023-07-27T13:23:27.222278Z",
     "shell.execute_reply": "2023-07-27T13:23:27.221193Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.210152Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_address_df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.224011Z",
     "iopub.status.busy": "2023-07-27T13:23:27.223664Z",
     "iopub.status.idle": "2023-07-27T13:23:27.962752Z",
     "shell.execute_reply": "2023-07-27T13:23:27.961453Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.223983Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are states have more than one formate\n",
    "# Victoria like VIC & New South Wales like NSW & QLD for Queensland\n",
    "# change it to one formate for each\n",
    "\n",
    "for x in customer_address_df.index :\n",
    "    if customer_address_df.loc[x, 'state'] == 'VIC' :\n",
    "        customer_address_df.loc[x, 'state'] = 'Victoria'\n",
    "    elif customer_address_df.loc[x, 'state'] == 'NSW' :\n",
    "        customer_address_df.loc[x, 'state'] = 'New South Wales'\n",
    "    elif customer_address_df.loc[x, 'state'] == 'QLD' :\n",
    "        customer_address_df.loc[x, 'state'] = 'Queensland'\n",
    "\n",
    "# check\n",
    "\n",
    "customer_address_df['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# customer_demographic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.965513Z",
     "iopub.status.busy": "2023-07-27T13:23:27.964479Z",
     "iopub.status.idle": "2023-07-27T13:23:27.984739Z",
     "shell.execute_reply": "2023-07-27T13:23:27.983361Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.965470Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:27.986625Z",
     "iopub.status.busy": "2023-07-27T13:23:27.986181Z",
     "iopub.status.idle": "2023-07-27T13:23:28.004314Z",
     "shell.execute_reply": "2023-07-27T13:23:28.002934Z",
     "shell.execute_reply.started": "2023-07-27T13:23:27.986586Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename column\n",
    "\n",
    "customer_demographic_df.columns = customer_demographic_df.iloc[0]\n",
    "customer_demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.006194Z",
     "iopub.status.busy": "2023-07-27T13:23:28.005804Z",
     "iopub.status.idle": "2023-07-27T13:23:28.027376Z",
     "shell.execute_reply": "2023-07-27T13:23:28.026207Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.006164Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop row[0]\n",
    "\n",
    "customer_demographic_df.drop(index= 0, axis= 0, inplace= True)\n",
    "customer_demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.029981Z",
     "iopub.status.busy": "2023-07-27T13:23:28.028871Z",
     "iopub.status.idle": "2023-07-27T13:23:28.047376Z",
     "shell.execute_reply": "2023-07-27T13:23:28.046051Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.029946Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset index\n",
    "\n",
    "customer_demographic_df = customer_demographic_df.reset_index()\n",
    "customer_demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.049596Z",
     "iopub.status.busy": "2023-07-27T13:23:28.049110Z",
     "iopub.status.idle": "2023-07-27T13:23:28.069489Z",
     "shell.execute_reply": "2023-07-27T13:23:28.068008Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.049554Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop column 'index'\n",
    "\n",
    "customer_demographic_df.drop(columns= 'index', axis= 0, inplace= True)\n",
    "customer_demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.071379Z",
     "iopub.status.busy": "2023-07-27T13:23:28.071068Z",
     "iopub.status.idle": "2023-07-27T13:23:28.078392Z",
     "shell.execute_reply": "2023-07-27T13:23:28.077670Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.071353Z"
    }
   },
   "outputs": [],
   "source": [
    "# check data types\n",
    "\n",
    "customer_demographic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.080065Z",
     "iopub.status.busy": "2023-07-27T13:23:28.079564Z",
     "iopub.status.idle": "2023-07-27T13:23:28.095326Z",
     "shell.execute_reply": "2023-07-27T13:23:28.094348Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.080036Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'customer_id' to int\n",
    "\n",
    "customer_demographic_df['customer_id'] = customer_demographic_df['customer_id'].astype(int)\n",
    "customer_demographic_df['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.097090Z",
     "iopub.status.busy": "2023-07-27T13:23:28.096660Z",
     "iopub.status.idle": "2023-07-27T13:23:28.110757Z",
     "shell.execute_reply": "2023-07-27T13:23:28.109524Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.097052Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'past_3_years_bike_related_purchases' to int\n",
    "\n",
    "customer_demographic_df['past_3_years_bike_related_purchases'] = customer_demographic_df['past_3_years_bike_related_purchases'].astype(int)\n",
    "customer_demographic_df['past_3_years_bike_related_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.112968Z",
     "iopub.status.busy": "2023-07-27T13:23:28.112374Z",
     "iopub.status.idle": "2023-07-27T13:23:28.124881Z",
     "shell.execute_reply": "2023-07-27T13:23:28.124087Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.112938Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'DOB' to datetime\n",
    "\n",
    "customer_demographic_df['DOB'] = pd.to_datetime(customer_demographic_df['DOB'])\n",
    "customer_demographic_df['DOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.126801Z",
     "iopub.status.busy": "2023-07-27T13:23:28.126248Z",
     "iopub.status.idle": "2023-07-27T13:23:28.140766Z",
     "shell.execute_reply": "2023-07-27T13:23:28.139738Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.126771Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'tenure' to float\n",
    "\n",
    "customer_demographic_df['tenure'] = customer_demographic_df['tenure'].astype(float)\n",
    "customer_demographic_df['tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.143260Z",
     "iopub.status.busy": "2023-07-27T13:23:28.142184Z",
     "iopub.status.idle": "2023-07-27T13:23:28.169883Z",
     "shell.execute_reply": "2023-07-27T13:23:28.168687Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.143220Z"
    }
   },
   "outputs": [],
   "source": [
    "# check NULL values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.171589Z",
     "iopub.status.busy": "2023-07-27T13:23:28.171186Z",
     "iopub.status.idle": "2023-07-27T13:23:28.179292Z",
     "shell.execute_reply": "2023-07-27T13:23:28.178186Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.171540Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to get missing data by 'customer_id' column\n",
    "\n",
    "customer_demographic_df['customer_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.181122Z",
     "iopub.status.busy": "2023-07-27T13:23:28.180729Z",
     "iopub.status.idle": "2023-07-27T13:23:28.208615Z",
     "shell.execute_reply": "2023-07-27T13:23:28.207889Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.181094Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Null values of 'job_industry_category' column\n",
    "\n",
    "customer_demographic_df = customer_demographic_df[customer_demographic_df['job_industry_category'].isnull() == False]\n",
    "print('NULL values = ', customer_demographic_df['job_industry_category'].isnull().sum())\n",
    "customer_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.210006Z",
     "iopub.status.busy": "2023-07-27T13:23:28.209655Z",
     "iopub.status.idle": "2023-07-27T13:23:28.230450Z",
     "shell.execute_reply": "2023-07-27T13:23:28.229186Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.209978Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.232691Z",
     "iopub.status.busy": "2023-07-27T13:23:28.232178Z",
     "iopub.status.idle": "2023-07-27T13:23:28.260757Z",
     "shell.execute_reply": "2023-07-27T13:23:28.259812Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.232649Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Null values of 'job_title' column\n",
    "\n",
    "customer_demographic_df = customer_demographic_df[customer_demographic_df['job_title'].isnull() == False]\n",
    "print('NULL values = ', customer_demographic_df['job_title'].isnull().sum())\n",
    "customer_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.263166Z",
     "iopub.status.busy": "2023-07-27T13:23:28.262342Z",
     "iopub.status.idle": "2023-07-27T13:23:28.284230Z",
     "shell.execute_reply": "2023-07-27T13:23:28.282878Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.263124Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.286855Z",
     "iopub.status.busy": "2023-07-27T13:23:28.286499Z",
     "iopub.status.idle": "2023-07-27T13:23:28.300124Z",
     "shell.execute_reply": "2023-07-27T13:23:28.298921Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.286807Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of data validity of 'default' column\n",
    "\n",
    "customer_demographic_df['default'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.301656Z",
     "iopub.status.busy": "2023-07-27T13:23:28.301351Z",
     "iopub.status.idle": "2023-07-27T13:23:28.325776Z",
     "shell.execute_reply": "2023-07-27T13:23:28.324702Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.301630Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop 'dufault' column\n",
    "\n",
    "customer_demographic_df.drop(columns= 'default', axis= 1, inplace= True)\n",
    "customer_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.328033Z",
     "iopub.status.busy": "2023-07-27T13:23:28.327199Z",
     "iopub.status.idle": "2023-07-27T13:23:28.348317Z",
     "shell.execute_reply": "2023-07-27T13:23:28.347316Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.328003Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.349963Z",
     "iopub.status.busy": "2023-07-27T13:23:28.349630Z",
     "iopub.status.idle": "2023-07-27T13:23:28.374975Z",
     "shell.execute_reply": "2023-07-27T13:23:28.373855Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.349935Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Null values of 'last_name' column\n",
    "\n",
    "customer_demographic_df = customer_demographic_df[customer_demographic_df['last_name'].isnull() == False]\n",
    "print('NULL values = ', customer_demographic_df['last_name'].isnull().sum())\n",
    "customer_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.376577Z",
     "iopub.status.busy": "2023-07-27T13:23:28.376261Z",
     "iopub.status.idle": "2023-07-27T13:23:28.393138Z",
     "shell.execute_reply": "2023-07-27T13:23:28.392015Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.376541Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.402144Z",
     "iopub.status.busy": "2023-07-27T13:23:28.401785Z",
     "iopub.status.idle": "2023-07-27T13:23:28.424362Z",
     "shell.execute_reply": "2023-07-27T13:23:28.423257Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.402115Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Null values of 'DOB' column\n",
    "\n",
    "customer_demographic_df = customer_demographic_df[customer_demographic_df['DOB'].isnull() == False]\n",
    "print('NULL values = ', customer_demographic_df['DOB'].isnull().sum())\n",
    "customer_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.426943Z",
     "iopub.status.busy": "2023-07-27T13:23:28.426367Z",
     "iopub.status.idle": "2023-07-27T13:23:28.444097Z",
     "shell.execute_reply": "2023-07-27T13:23:28.442973Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.426901Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "customer_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.445908Z",
     "iopub.status.busy": "2023-07-27T13:23:28.445568Z",
     "iopub.status.idle": "2023-07-27T13:23:28.461874Z",
     "shell.execute_reply": "2023-07-27T13:23:28.460468Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.445871Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of duplicated values\n",
    "\n",
    "customer_demographic_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.463928Z",
     "iopub.status.busy": "2023-07-27T13:23:28.463135Z",
     "iopub.status.idle": "2023-07-27T13:23:28.471952Z",
     "shell.execute_reply": "2023-07-27T13:23:28.470872Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.463894Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of data validity of 'gender' column\n",
    "\n",
    "customer_demographic_df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.474269Z",
     "iopub.status.busy": "2023-07-27T13:23:28.473581Z",
     "iopub.status.idle": "2023-07-27T13:23:28.587164Z",
     "shell.execute_reply": "2023-07-27T13:23:28.586002Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.474227Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are more than one formate for some records..\n",
    "# 'F' & 'Femal' like 'Female'..\n",
    "# change it to one formate for each record.\n",
    "\n",
    "for x in customer_demographic_df.index :\n",
    "    if customer_demographic_df.loc[x, 'gender'] == 'F' :\n",
    "        customer_demographic_df.loc[x, 'gender'] = 'Female'\n",
    "    elif customer_demographic_df.loc[x, 'gender'] == 'Femal' :\n",
    "        customer_demographic_df.loc[x, 'gender'] = 'Female'\n",
    "\n",
    "# drop records = 'U'\n",
    "\n",
    "customer_demographic_df = customer_demographic_df[customer_demographic_df['gender'] != 'U']\n",
    "\n",
    "# check\n",
    "\n",
    "customer_demographic_df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.589610Z",
     "iopub.status.busy": "2023-07-27T13:23:28.588651Z",
     "iopub.status.idle": "2023-07-27T13:23:28.596348Z",
     "shell.execute_reply": "2023-07-27T13:23:28.595331Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.589577Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of data validity of 'customer_id' column..\n",
    "# customers who are not in customer_address_df are not valid.\n",
    "\n",
    "customer_address_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.598044Z",
     "iopub.status.busy": "2023-07-27T13:23:28.597720Z",
     "iopub.status.idle": "2023-07-27T13:23:28.611808Z",
     "shell.execute_reply": "2023-07-27T13:23:28.610913Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.598018Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_demographic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.613471Z",
     "iopub.status.busy": "2023-07-27T13:23:28.613068Z",
     "iopub.status.idle": "2023-07-27T13:23:28.648709Z",
     "shell.execute_reply": "2023-07-27T13:23:28.647568Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.613433Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge 'customer_address_df' & 'customer_demographic_df' in one df and drop not valid.\n",
    "\n",
    "df = pd.merge(customer_address_df, customer_demographic_df, on= 'customer_id')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.651525Z",
     "iopub.status.busy": "2023-07-27T13:23:28.651203Z",
     "iopub.status.idle": "2023-07-27T13:23:28.669571Z",
     "shell.execute_reply": "2023-07-27T13:23:28.668596Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.651485Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.671114Z",
     "iopub.status.busy": "2023-07-27T13:23:28.670746Z",
     "iopub.status.idle": "2023-07-27T13:23:28.689851Z",
     "shell.execute_reply": "2023-07-27T13:23:28.688878Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.671073Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "transaction_df.columns = transaction_df.iloc[0]\n",
    "transaction_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.691572Z",
     "iopub.status.busy": "2023-07-27T13:23:28.691240Z",
     "iopub.status.idle": "2023-07-27T13:23:28.718147Z",
     "shell.execute_reply": "2023-07-27T13:23:28.717118Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.691544Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop row[0]\n",
    "\n",
    "transaction_df.drop(index= 0, axis= 0, inplace= True)\n",
    "transaction_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.720163Z",
     "iopub.status.busy": "2023-07-27T13:23:28.719853Z",
     "iopub.status.idle": "2023-07-27T13:23:28.737232Z",
     "shell.execute_reply": "2023-07-27T13:23:28.736144Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.720137Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset index\n",
    "\n",
    "transaction_df.reset_index(inplace= True)\n",
    "transaction_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.739345Z",
     "iopub.status.busy": "2023-07-27T13:23:28.738964Z",
     "iopub.status.idle": "2023-07-27T13:23:28.763816Z",
     "shell.execute_reply": "2023-07-27T13:23:28.763015Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.739314Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop 'index' column\n",
    "\n",
    "transaction_df.drop(columns= 'index', axis= 1, inplace= True)\n",
    "transaction_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.765656Z",
     "iopub.status.busy": "2023-07-27T13:23:28.765313Z",
     "iopub.status.idle": "2023-07-27T13:23:28.779182Z",
     "shell.execute_reply": "2023-07-27T13:23:28.778210Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.765626Z"
    }
   },
   "outputs": [],
   "source": [
    "# check of data types\n",
    "\n",
    "transaction_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.782716Z",
     "iopub.status.busy": "2023-07-27T13:23:28.781999Z",
     "iopub.status.idle": "2023-07-27T13:23:28.800112Z",
     "shell.execute_reply": "2023-07-27T13:23:28.798976Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.782674Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'transaction_id' to int\n",
    "\n",
    "transaction_df.transaction_id = transaction_df.transaction_id.astype(int)\n",
    "transaction_df.transaction_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.802167Z",
     "iopub.status.busy": "2023-07-27T13:23:28.801769Z",
     "iopub.status.idle": "2023-07-27T13:23:28.821564Z",
     "shell.execute_reply": "2023-07-27T13:23:28.820202Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.802135Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'product_id' to int\n",
    "\n",
    "transaction_df.product_id = transaction_df.product_id.astype(int)\n",
    "transaction_df.product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.823334Z",
     "iopub.status.busy": "2023-07-27T13:23:28.822993Z",
     "iopub.status.idle": "2023-07-27T13:23:28.847806Z",
     "shell.execute_reply": "2023-07-27T13:23:28.846559Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.823305Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'transaction_date' to datetime\n",
    "\n",
    "transaction_df.transaction_date = pd.to_datetime(transaction_df.transaction_date)\n",
    "transaction_df.transaction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.849901Z",
     "iopub.status.busy": "2023-07-27T13:23:28.849395Z",
     "iopub.status.idle": "2023-07-27T13:23:28.864549Z",
     "shell.execute_reply": "2023-07-27T13:23:28.863429Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.849833Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'list_price' to float\n",
    "\n",
    "transaction_df.list_price = transaction_df.list_price.astype(float)\n",
    "transaction_df.list_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.866263Z",
     "iopub.status.busy": "2023-07-27T13:23:28.865929Z",
     "iopub.status.idle": "2023-07-27T13:23:28.885527Z",
     "shell.execute_reply": "2023-07-27T13:23:28.884427Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.866234Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'standard_cost' to float\n",
    "\n",
    "transaction_df.standard_cost = transaction_df.standard_cost.astype(float)\n",
    "transaction_df.standard_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.887484Z",
     "iopub.status.busy": "2023-07-27T13:23:28.887074Z",
     "iopub.status.idle": "2023-07-27T13:23:28.915743Z",
     "shell.execute_reply": "2023-07-27T13:23:28.914799Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.887446Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert 'product_first_sold_date' to datetime\n",
    "\n",
    "transaction_df.product_first_sold_date = pd.to_datetime(\n",
    "    transaction_df.product_first_sold_date, format='%d%m%y', exact= False, errors='raise', utc= True, infer_datetime_format= False)\n",
    "\n",
    "transaction_df.product_first_sold_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.917795Z",
     "iopub.status.busy": "2023-07-27T13:23:28.917356Z",
     "iopub.status.idle": "2023-07-27T13:23:28.933712Z",
     "shell.execute_reply": "2023-07-27T13:23:28.932529Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.917746Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore records that year greater than 2023\n",
    "\n",
    "transaction_df.product_first_sold_date = transaction_df.product_first_sold_date[transaction_df.product_first_sold_date.dt.year<2023]\n",
    "transaction_df.product_first_sold_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.935498Z",
     "iopub.status.busy": "2023-07-27T13:23:28.935127Z",
     "iopub.status.idle": "2023-07-27T13:23:28.993067Z",
     "shell.execute_reply": "2023-07-27T13:23:28.991913Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.935468Z"
    }
   },
   "outputs": [],
   "source": [
    "# check Null values\n",
    "\n",
    "transaction_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:28.995709Z",
     "iopub.status.busy": "2023-07-27T13:23:28.994769Z",
     "iopub.status.idle": "2023-07-27T13:23:29.001413Z",
     "shell.execute_reply": "2023-07-27T13:23:29.000371Z",
     "shell.execute_reply.started": "2023-07-27T13:23:28.995672Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.002883Z",
     "iopub.status.busy": "2023-07-27T13:23:29.002575Z",
     "iopub.status.idle": "2023-07-27T13:23:29.020302Z",
     "shell.execute_reply": "2023-07-27T13:23:29.019093Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.002857Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop NaT records\n",
    "\n",
    "transaction_df = transaction_df[transaction_df.product_first_sold_date.isnull() == False]\n",
    "\n",
    "# check\n",
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.022551Z",
     "iopub.status.busy": "2023-07-27T13:23:29.022211Z",
     "iopub.status.idle": "2023-07-27T13:23:29.062013Z",
     "shell.execute_reply": "2023-07-27T13:23:29.060698Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.022523Z"
    }
   },
   "outputs": [],
   "source": [
    "# check remaining Null values\n",
    "\n",
    "transaction_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.064141Z",
     "iopub.status.busy": "2023-07-27T13:23:29.063739Z",
     "iopub.status.idle": "2023-07-27T13:23:29.074169Z",
     "shell.execute_reply": "2023-07-27T13:23:29.073035Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.064111Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to find missing values by 'transaction_id' column\n",
    "\n",
    "transaction_df.transaction_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.076045Z",
     "iopub.status.busy": "2023-07-27T13:23:29.075669Z",
     "iopub.status.idle": "2023-07-27T13:23:29.104448Z",
     "shell.execute_reply": "2023-07-27T13:23:29.103294Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.076013Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Null values\n",
    "\n",
    "transaction_df = transaction_df[transaction_df['online_order'].isnull() == False]\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.106240Z",
     "iopub.status.busy": "2023-07-27T13:23:29.105903Z",
     "iopub.status.idle": "2023-07-27T13:23:29.149877Z",
     "shell.execute_reply": "2023-07-27T13:23:29.148849Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.106211Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge df & transaction_df in one df and drop invalid customer\n",
    "\n",
    "df = pd.merge(df, transaction_df, on= 'customer_id')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.151718Z",
     "iopub.status.busy": "2023-07-27T13:23:29.151326Z",
     "iopub.status.idle": "2023-07-27T13:23:29.209653Z",
     "shell.execute_reply": "2023-07-27T13:23:29.208543Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.151687Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:23:29.211244Z",
     "iopub.status.busy": "2023-07-27T13:23:29.210913Z",
     "iopub.status.idle": "2023-07-27T13:23:42.793608Z",
     "shell.execute_reply": "2023-07-27T13:23:42.792491Z",
     "shell.execute_reply.started": "2023-07-27T13:23:29.211217Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:25:27.898919Z",
     "iopub.status.busy": "2023-07-27T13:25:27.897884Z",
     "iopub.status.idle": "2023-07-27T13:25:27.905323Z",
     "shell.execute_reply": "2023-07-27T13:25:27.903775Z",
     "shell.execute_reply.started": "2023-07-27T13:25:27.898882Z"
    }
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:25:41.333204Z",
     "iopub.status.busy": "2023-07-27T13:25:41.332787Z",
     "iopub.status.idle": "2023-07-27T13:26:40.857048Z",
     "shell.execute_reply": "2023-07-27T13:26:40.856079Z",
     "shell.execute_reply.started": "2023-07-27T13:25:41.333174Z"
    }
   },
   "outputs": [],
   "source": [
    "ProfileReport(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
